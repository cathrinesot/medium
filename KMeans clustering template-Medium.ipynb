{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans clustering Medium Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in your CSV with the text column if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from dirtyclean import clean\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"top_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>filename</th>\n",
       "      <th>followers</th>\n",
       "      <th>description</th>\n",
       "      <th>claps</th>\n",
       "      <th>people_clapped</th>\n",
       "      <th>min_read</th>\n",
       "      <th>high_text</th>\n",
       "      <th>author_date</th>\n",
       "      <th>date</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Spector</td>\n",
       "      <td>You’re busy, so I’ll keep this quick.\\nFollowi...</td>\n",
       "      <td>3.The Two Minutes It Takes To Read This Will I...</td>\n",
       "      <td>27000</td>\n",
       "      <td>Writer. Strategist. For The Interested newslet...</td>\n",
       "      <td>25191</td>\n",
       "      <td>17953</td>\n",
       "      <td>2</td>\n",
       "      <td>Delete the word “that.”</td>\n",
       "      <td>Apr 2017</td>\n",
       "      <td>Jul 22, 2016</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Lapinski</td>\n",
       "      <td>rump Is What Happens When You Nominate A Cheat...</td>\n",
       "      <td>8.Dear Democrats, Read This If You Do Not Unde...</td>\n",
       "      <td>13400</td>\n",
       "      <td>Tech Entrepreneur. Journalist. Technologist. C...</td>\n",
       "      <td>10885</td>\n",
       "      <td>9981</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the problem with America today, the te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nov 9, 2016</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shem Magnezi</td>\n",
       "      <td>That’s right, I said it.\\n\\nFuck your startup ...</td>\n",
       "      <td>2.Fuck You Startup World</td>\n",
       "      <td>6200</td>\n",
       "      <td>Doing what I love</td>\n",
       "      <td>22661</td>\n",
       "      <td>17316</td>\n",
       "      <td>5</td>\n",
       "      <td>You should celebrate any day that you don’t ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 11, 2016</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tobias Stone</td>\n",
       "      <td>It seems we’re entering another of those stupi...</td>\n",
       "      <td>1.History tells us what may happen next with B...</td>\n",
       "      <td>27000</td>\n",
       "      <td>Writing about politics, history, and society. ...</td>\n",
       "      <td>18983</td>\n",
       "      <td>17092</td>\n",
       "      <td>7</td>\n",
       "      <td>We need to find a way to bridge from our close...</td>\n",
       "      <td>Aug 2017</td>\n",
       "      <td>Jul 23, 2016</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Max Braun</td>\n",
       "      <td>When I couldn’t buy a smart mirror and made on...</td>\n",
       "      <td>10.My Bathroom Mirror Is Smarter Than Yours</td>\n",
       "      <td>7400</td>\n",
       "      <td>Inevitable technology. Lately robots at X.</td>\n",
       "      <td>10353</td>\n",
       "      <td>9506</td>\n",
       "      <td>3</td>\n",
       "      <td>Maybe I’ll post a more detailed making-of with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan 30, 2016</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                               body  \\\n",
       "0    Josh Spector  You’re busy, so I’ll keep this quick.\\nFollowi...   \n",
       "1  Trent Lapinski  rump Is What Happens When You Nominate A Cheat...   \n",
       "2    Shem Magnezi  That’s right, I said it.\\n\\nFuck your startup ...   \n",
       "3    Tobias Stone  It seems we’re entering another of those stupi...   \n",
       "4       Max Braun  When I couldn’t buy a smart mirror and made on...   \n",
       "\n",
       "                                            filename  followers  \\\n",
       "0  3.The Two Minutes It Takes To Read This Will I...      27000   \n",
       "1  8.Dear Democrats, Read This If You Do Not Unde...      13400   \n",
       "2                           2.Fuck You Startup World       6200   \n",
       "3  1.History tells us what may happen next with B...      27000   \n",
       "4        10.My Bathroom Mirror Is Smarter Than Yours       7400   \n",
       "\n",
       "                                         description  claps  people_clapped  \\\n",
       "0  Writer. Strategist. For The Interested newslet...  25191           17953   \n",
       "1  Tech Entrepreneur. Journalist. Technologist. C...  10885            9981   \n",
       "2                                  Doing what I love  22661           17316   \n",
       "3  Writing about politics, history, and society. ...  18983           17092   \n",
       "4         Inevitable technology. Lately robots at X.  10353            9506   \n",
       "\n",
       "   min_read                                          high_text author_date  \\\n",
       "0         2                            Delete the word “that.”    Apr 2017   \n",
       "1         5  This is the problem with America today, the te...         NaN   \n",
       "2         5  You should celebrate any day that you don’t ha...         NaN   \n",
       "3         7  We need to find a way to bridge from our close...    Aug 2017   \n",
       "4         3  Maybe I’ll post a more detailed making-of with...         NaN   \n",
       "\n",
       "           date images  \n",
       "0  Jul 22, 2016    Yes  \n",
       "1   Nov 9, 2016    Yes  \n",
       "2  Oct 11, 2016    Yes  \n",
       "3  Jul 23, 2016    Yes  \n",
       "4  Jan 30, 2016    Yes  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author            object\n",
       "body              object\n",
       "filename          object\n",
       "followers          int64\n",
       "description       object\n",
       "claps              int64\n",
       "people_clapped     int64\n",
       "min_read           int64\n",
       "high_text         object\n",
       "author_date       object\n",
       "date              object\n",
       "images            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"body\"] = df[\"body\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    6\n",
       "2    7\n",
       "3    8\n",
       "dtype: int32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize your documents\n",
    "\n",
    "What are the options when creating a `TfidfVectorizer`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `TfidfVectorizer` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think about:\n",
    "* **ngram_range: Do we just want single words? Or more? (1,2) is one- and two-word phrases, etc.\n",
    "* **max_features**: Can it make things faster? `1` and up\n",
    "* **max_df**: Should we ignore words that show up too often? `0.0`-`1.0` for percent, OR an integer for absolute document counts\n",
    "* **min_df**: Should we ignore words that show up too little? `0.0`-`1.0` for percent, OR an integer for absolute document counts\n",
    "* **vocabulary**: Only care about certain words\n",
    "\n",
    "Also... how many documents do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.02 s, sys: 17.5 ms, total: 1.03 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "# Vectorize and save into a new dataframe\n",
    "vec = TfidfVectorizer(tokenizer=textblob_tokenizer,\n",
    "                      stop_words='english',\n",
    "                      max_df= 0.9, #if you're in >90%, ignore\n",
    "                      min_df= 0.15, #if you're in 15%, ignore\n",
    "                      use_idf=True)\n",
    "\n",
    "# Fit from the 'text' column of our dataframe\n",
    "matrix = vec.fit_transform(df['body'])\n",
    "\n",
    "# Then turn it into a new dataframe\n",
    "results = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52.6 ms, sys: 1.51 ms, total: 54.1 ms\n",
      "Wall time: 58.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "#diwxame to textblob giati argei\n",
    "def textblob_tokenizer(str_input):\n",
    "    blob = TextBlob(str_input.lower())\n",
    "    tokens = blob.words\n",
    "    words = [token.stem() for token in tokens]\n",
    "    return words\n",
    "\n",
    "# Vectorize and save into a new dataframe\n",
    "vec = TfidfVectorizer(stop_words='english',\n",
    "                      max_df= 0.9, #if you're in >90%, ignore\n",
    "                      use_idf=True)\n",
    "\n",
    "# Fit from the 'text' column of our dataframe\n",
    "matrix = vec.fit_transform(df['body'])\n",
    "\n",
    "# Then turn it into a new dataframe\n",
    "results = pd.DataFrame(matrix.toarray(), columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>12</th>\n",
       "      <th>130</th>\n",
       "      <th>140</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>yoy</th>\n",
       "      <th>zero</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zucks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021363</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.022742</td>\n",
       "      <td>0.022742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017223</td>\n",
       "      <td>0.02026</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000        10       100   12       130  140        15  150   16        17  \\\n",
       "0  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "1  0.0  0.021363  0.024028  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "2  0.0  0.000000  0.033828  0.0  0.022742  0.0  0.022742  0.0  0.0  0.019333   \n",
       "3  0.0  0.000000  0.030136  0.0  0.000000  0.0  0.000000  0.0  0.0  0.017223   \n",
       "4  0.0  0.000000  0.000000  0.0  0.000000  0.0  0.000000  0.0  0.0  0.000000   \n",
       "\n",
       "     ...     yesterday      york  young  youtube       yoy  zero      zoom  \\\n",
       "0    ...           0.0  0.000000    0.0      0.0  0.000000   0.0  0.000000   \n",
       "1    ...           0.0  0.024028    0.0      0.0  0.000000   0.0  0.000000   \n",
       "2    ...           0.0  0.000000    0.0      0.0  0.022742   0.0  0.000000   \n",
       "3    ...           0.0  0.015068    0.0      0.0  0.000000   0.0  0.017223   \n",
       "4    ...           0.0  0.000000    0.0      0.0  0.000000   0.0  0.000000   \n",
       "\n",
       "   zooming      zuck     zucks  \n",
       "0  0.00000  0.000000  0.000000  \n",
       "1  0.00000  0.000000  0.000000  \n",
       "2  0.00000  0.022742  0.022742  \n",
       "3  0.02026  0.000000  0.000000  \n",
       "4  0.00000  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 2922 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ...Try it without the TextBlob tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster your documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 clusters usinga  (10, 2922) matrix\n",
      "CPU times: user 165 ms, sys: 4.13 ms, total: 169 ms\n",
      "Wall time: 169 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# How many clusters?\n",
    "number_of_clusters=3\n",
    "km = KMeans(n_clusters=number_of_clusters)\n",
    "\n",
    "print(\"Fitting\", number_of_clusters, \"clusters usinga \", matrix.shape, \"matrix\")\n",
    "\n",
    "# Let's fit it!\n",
    "km.fit(matrix)\n",
    "km.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See what they look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0: people trump just news mirror need use way\n",
      "Cluster 1: sentence ross word sentences example short nerds adds\n",
      "Cluster 2: fuck fucking shit solution goddamn know just want\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vec.get_feature_names()\n",
    "for i in range(number_of_clusters):\n",
    "    top_ten_words = [terms[ind] for ind in order_centroids[i, :8]]\n",
    "    print(\"Cluster {}: {}\".format(i, ' '.join(top_ten_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the category back to the original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>filename</th>\n",
       "      <th>followers</th>\n",
       "      <th>description</th>\n",
       "      <th>claps</th>\n",
       "      <th>people_clapped</th>\n",
       "      <th>min_read</th>\n",
       "      <th>high_text</th>\n",
       "      <th>author_date</th>\n",
       "      <th>date</th>\n",
       "      <th>images</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Spector</td>\n",
       "      <td>You’re busy, so I’ll keep this quick.\\nFollowi...</td>\n",
       "      <td>3.The Two Minutes It Takes To Read This Will I...</td>\n",
       "      <td>27000</td>\n",
       "      <td>Writer. Strategist. For The Interested newslet...</td>\n",
       "      <td>25191</td>\n",
       "      <td>17953</td>\n",
       "      <td>2</td>\n",
       "      <td>Delete the word “that.”</td>\n",
       "      <td>Apr 2017</td>\n",
       "      <td>Jul 22, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Lapinski</td>\n",
       "      <td>rump Is What Happens When You Nominate A Cheat...</td>\n",
       "      <td>8.Dear Democrats, Read This If You Do Not Unde...</td>\n",
       "      <td>13400</td>\n",
       "      <td>Tech Entrepreneur. Journalist. Technologist. C...</td>\n",
       "      <td>10885</td>\n",
       "      <td>9981</td>\n",
       "      <td>5</td>\n",
       "      <td>This is the problem with America today, the te...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nov 9, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shem Magnezi</td>\n",
       "      <td>That’s right, I said it.\\n\\nFuck your startup ...</td>\n",
       "      <td>2.Fuck You Startup World</td>\n",
       "      <td>6200</td>\n",
       "      <td>Doing what I love</td>\n",
       "      <td>22661</td>\n",
       "      <td>17316</td>\n",
       "      <td>5</td>\n",
       "      <td>You should celebrate any day that you don’t ha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oct 11, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tobias Stone</td>\n",
       "      <td>It seems we’re entering another of those stupi...</td>\n",
       "      <td>1.History tells us what may happen next with B...</td>\n",
       "      <td>27000</td>\n",
       "      <td>Writing about politics, history, and society. ...</td>\n",
       "      <td>18983</td>\n",
       "      <td>17092</td>\n",
       "      <td>7</td>\n",
       "      <td>We need to find a way to bridge from our close...</td>\n",
       "      <td>Aug 2017</td>\n",
       "      <td>Jul 23, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Max Braun</td>\n",
       "      <td>When I couldn’t buy a smart mirror and made on...</td>\n",
       "      <td>10.My Bathroom Mirror Is Smarter Than Yours</td>\n",
       "      <td>7400</td>\n",
       "      <td>Inevitable technology. Lately robots at X.</td>\n",
       "      <td>10353</td>\n",
       "      <td>9506</td>\n",
       "      <td>3</td>\n",
       "      <td>Maybe I’ll post a more detailed making-of with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jan 30, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hillary Clinton [parody]</td>\n",
       "      <td>What the fuck is your problem, America??\\nI’m ...</td>\n",
       "      <td>6.Let Me Remind You Fuckers Who I Am</td>\n",
       "      <td>12500</td>\n",
       "      <td>45th President of the United States, patriarch...</td>\n",
       "      <td>12081</td>\n",
       "      <td>11415</td>\n",
       "      <td>4</td>\n",
       "      <td>“Oh but what about your eeeemaaaaillls???” Shu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jul 25, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jose Aguinaga</td>\n",
       "      <td>No JavaScript frameworks were created during t...</td>\n",
       "      <td>4.How it feels to learn JavaScript in 2016</td>\n",
       "      <td>8700</td>\n",
       "      <td>Web Engineer.</td>\n",
       "      <td>33715</td>\n",
       "      <td>18783</td>\n",
       "      <td>13</td>\n",
       "      <td>I need to display data on a page, not perform ...</td>\n",
       "      <td>May 2017</td>\n",
       "      <td>Oct 3, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jose Aguinaga</td>\n",
       "      <td>It’s easier to fool people than to convince th...</td>\n",
       "      <td>7.How Technology is Hijacking Your Mind — from...</td>\n",
       "      <td>15100</td>\n",
       "      <td>Co-founder, Center for Humane Technology // Ex...</td>\n",
       "      <td>21025</td>\n",
       "      <td>12638</td>\n",
       "      <td>16</td>\n",
       "      <td>We need our smartphones, notifications screens...</td>\n",
       "      <td>Jul 2017</td>\n",
       "      <td>May 18, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Hopkins</td>\n",
       "      <td>I want to discuss a popular TV show my wife an...</td>\n",
       "      <td>5.How a TV Sitcom Triggered the Downfall of We...</td>\n",
       "      <td>9800</td>\n",
       "      <td>I write a little bit of everything—short stori...</td>\n",
       "      <td>18489</td>\n",
       "      <td>15529</td>\n",
       "      <td>6</td>\n",
       "      <td>I see Kim Kardashian’s ass at the top of CNN.c...</td>\n",
       "      <td>Sep 2017</td>\n",
       "      <td>Mar 22, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tristan de Montebello</td>\n",
       "      <td>Almost every day I sit down in a coffee shop i...</td>\n",
       "      <td>9.What are people working on in coffee shops</td>\n",
       "      <td>2600</td>\n",
       "      <td>I teach adult beginners how to learn guitar in...</td>\n",
       "      <td>10395</td>\n",
       "      <td>9720</td>\n",
       "      <td>5</td>\n",
       "      <td>It felt absolutely amazing to connect with all...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>May 10, 2016</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author  \\\n",
       "0              Josh Spector   \n",
       "1            Trent Lapinski   \n",
       "2              Shem Magnezi   \n",
       "3              Tobias Stone   \n",
       "4                 Max Braun   \n",
       "5  Hillary Clinton [parody]   \n",
       "6             Jose Aguinaga   \n",
       "7             Jose Aguinaga   \n",
       "8             David Hopkins   \n",
       "9     Tristan de Montebello   \n",
       "\n",
       "                                                body  \\\n",
       "0  You’re busy, so I’ll keep this quick.\\nFollowi...   \n",
       "1  rump Is What Happens When You Nominate A Cheat...   \n",
       "2  That’s right, I said it.\\n\\nFuck your startup ...   \n",
       "3  It seems we’re entering another of those stupi...   \n",
       "4  When I couldn’t buy a smart mirror and made on...   \n",
       "5  What the fuck is your problem, America??\\nI’m ...   \n",
       "6  No JavaScript frameworks were created during t...   \n",
       "7  It’s easier to fool people than to convince th...   \n",
       "8  I want to discuss a popular TV show my wife an...   \n",
       "9  Almost every day I sit down in a coffee shop i...   \n",
       "\n",
       "                                            filename  followers  \\\n",
       "0  3.The Two Minutes It Takes To Read This Will I...      27000   \n",
       "1  8.Dear Democrats, Read This If You Do Not Unde...      13400   \n",
       "2                           2.Fuck You Startup World       6200   \n",
       "3  1.History tells us what may happen next with B...      27000   \n",
       "4        10.My Bathroom Mirror Is Smarter Than Yours       7400   \n",
       "5               6.Let Me Remind You Fuckers Who I Am      12500   \n",
       "6         4.How it feels to learn JavaScript in 2016       8700   \n",
       "7  7.How Technology is Hijacking Your Mind — from...      15100   \n",
       "8  5.How a TV Sitcom Triggered the Downfall of We...       9800   \n",
       "9       9.What are people working on in coffee shops       2600   \n",
       "\n",
       "                                         description  claps  people_clapped  \\\n",
       "0  Writer. Strategist. For The Interested newslet...  25191           17953   \n",
       "1  Tech Entrepreneur. Journalist. Technologist. C...  10885            9981   \n",
       "2                                  Doing what I love  22661           17316   \n",
       "3  Writing about politics, history, and society. ...  18983           17092   \n",
       "4         Inevitable technology. Lately robots at X.  10353            9506   \n",
       "5  45th President of the United States, patriarch...  12081           11415   \n",
       "6                                      Web Engineer.  33715           18783   \n",
       "7  Co-founder, Center for Humane Technology // Ex...  21025           12638   \n",
       "8  I write a little bit of everything—short stori...  18489           15529   \n",
       "9  I teach adult beginners how to learn guitar in...  10395            9720   \n",
       "\n",
       "   min_read                                          high_text author_date  \\\n",
       "0         2                            Delete the word “that.”    Apr 2017   \n",
       "1         5  This is the problem with America today, the te...         NaN   \n",
       "2         5  You should celebrate any day that you don’t ha...         NaN   \n",
       "3         7  We need to find a way to bridge from our close...    Aug 2017   \n",
       "4         3  Maybe I’ll post a more detailed making-of with...         NaN   \n",
       "5         4  “Oh but what about your eeeemaaaaillls???” Shu...         NaN   \n",
       "6        13  I need to display data on a page, not perform ...    May 2017   \n",
       "7        16  We need our smartphones, notifications screens...    Jul 2017   \n",
       "8         6  I see Kim Kardashian’s ass at the top of CNN.c...    Sep 2017   \n",
       "9         5  It felt absolutely amazing to connect with all...         NaN   \n",
       "\n",
       "           date images  category  \n",
       "0  Jul 22, 2016    Yes         1  \n",
       "1   Nov 9, 2016    Yes         0  \n",
       "2  Oct 11, 2016    Yes         2  \n",
       "3  Jul 23, 2016    Yes         0  \n",
       "4  Jan 30, 2016    Yes         0  \n",
       "5  Jul 25, 2016    Yes         2  \n",
       "6   Oct 3, 2016    Yes         0  \n",
       "7  May 18, 2016    Yes         0  \n",
       "8  Mar 22, 2016    Yes         1  \n",
       "9  May 10, 2016    Yes         0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'] = km.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be pleased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#['said', 'thee', 'ye'] + list(stop_words.ENGLISH_STOP_WORDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
